{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f20ae054-90c8-4cfa-aa5d-040374ec97f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1pFxorg8Mz5U"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff079223-94f2-46e4-83f3-271eec4420c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiWLFVIKE9_U",
    "outputId": "09421133-c37c-42c9-bc0b-75ec48af30c3"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pyspark==3.4.1 spark-nlp==5.4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd939553-6bcb-4c2a-98d5-2e90640b5d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUmAa0RUFSFl",
    "outputId": "f95139f9-2911-4f7d-bc0c-06f06e041872"
   },
   "outputs": [],
   "source": [
    " #Spark NLP Initialization\n",
    "\n",
    "try:\n",
    "    import sparknlp\n",
    "    spark = sparknlp.start()\n",
    "    print(\"‚úÖ Spark NLP started successfully\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    raise ModuleNotFoundError(\n",
    "        \"‚ùå Spark NLP not found.\\n\"\n",
    "        \"üëâ Run: pip install spark-nlp\\n\"\n",
    "        \"üëâ Restart runtime after install.\"\n",
    "    ) from e\n",
    "\n",
    "\n",
    "except RuntimeError as e:\n",
    "    if \"Spark Connect server and Spark master cannot be configured together\" in str(e):\n",
    "        raise RuntimeError(\n",
    "            \"‚ùå Spark Connect conflict detected.\\n\"\n",
    "            \"üëâ Do NOT call sparknlp.start() in Databricks.\\n\"\n",
    "            \"üëâ Use existing SparkSession instead.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    if \"Java gateway process exited\" in str(e):\n",
    "        raise RuntimeError(\n",
    "            \"‚ùå Java/JVM failed to start.\\n\"\n",
    "            \"üëâ Ensure Java 8 or 11 is installed.\\n\"\n",
    "            \"üëâ Restart the runtime.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "    elif \"spark.jsl.settings.pretrained.cache_folder\" in str(e):\n",
    "        raise RuntimeError(\n",
    "            \"‚ùå Spark NLP cache configuration error.\\n\"\n",
    "            \"üëâ Do NOT set spark.jsl.settings.pretrained.cache_folder manually.\\n\"\n",
    "            \"üëâ Use environment variable SPARK_NLP_CACHE instead.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "    elif \"OutOfMemoryError\" in str(e):\n",
    "        raise RuntimeError(\n",
    "            \"‚ùå Out of Memory error.\\n\"\n",
    "            \"üëâ Reduce batch size or increase driver memory.\"\n",
    "        ) from e\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(f\"‚ùå Spark NLP init failed: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a170ef8-457c-4c8f-ab6f-52a6900fefc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "k6fwoUZzL2CM"
   },
   "outputs": [],
   "source": [
    "from sparknlp.annotator import ClassifierDLModel\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3de2078e-2b85-43c8-91e2-857e7ad6a6de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BIXmmRAnFYpj",
    "outputId": "4b70563f-71a6-4bf9-93a1-1374c874a24a"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "try:\n",
    "    from sparknlp.base import DocumentAssembler\n",
    "    from sparknlp.annotator import (\n",
    "        Tokenizer,\n",
    "        UniversalSentenceEncoder,\n",
    "        SentimentDLModel\n",
    "    )\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "    print(\"‚úÖ Imports successful\")\n",
    "\n",
    "except ModuleNotFoundError as e:\n",
    "    if \"sparknlp\" in str(e):\n",
    "        raise ModuleNotFoundError(\n",
    "            \"‚ùå Spark NLP not installed.\\n\"\n",
    "            \"üëâ Fix: pip install spark-nlp\\n\"\n",
    "            \"üëâ Restart runtime after installation.\"\n",
    "        ) from e\n",
    "    elif \"pyspark\" in str(e):\n",
    "        raise ModuleNotFoundError(\n",
    "            \"‚ùå PySpark not installed.\\n\"\n",
    "            \"üëâ Fix: pip install pyspark\\n\"\n",
    "            \"üëâ Restart runtime.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "\n",
    "except ImportError as e:\n",
    "    if \"UniversalSentenceEncoder\" in str(e):\n",
    "        raise ImportError(\n",
    "            \"‚ùå UniversalSentenceEncoder not available.\\n\"\n",
    "            \"üëâ Spark NLP version too old.\\n\"\n",
    "            \"üëâ Upgrade: pip install --upgrade spark-nlp\"\n",
    "        ) from e\n",
    "    elif \"SentimentDLModel\" in str(e):\n",
    "        raise ImportError(\n",
    "            \"‚ùå SentimentDLModel not found.\\n\"\n",
    "            \"üëâ Spark NLP ML annotators not available in this version.\\n\"\n",
    "            \"üëâ Upgrade Spark NLP.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "except Exception as e:\n",
    "    if \"JavaPackage\" in str(e):\n",
    "        raise RuntimeError(\n",
    "            \"‚ùå Spark NLP JVM classes not loaded.\\n\"\n",
    "            \"üëâ Spark session not initialized correctly.\\n\"\n",
    "            \"üëâ Ensure sparknlp.start() ran successfully.\"\n",
    "        ) from e\n",
    "    else:\n",
    "        raise RuntimeError(f\"‚ùå Import failed: {e}\") from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5d3e878-8c5b-4fcb-aac7-d52ab7e1e3e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XC_IGw1IGNit"
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(\"/content/sliver_layer__1_ (1).csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8cc610cb-8222-4dda-af0d-689cb34cc562",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWgiHYcjJGlx",
    "outputId": "5cad6a3b-9fd7-40f2-e7c6-4ddbf7270dde"
   },
   "outputs": [],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f51a1081-7881-4f6f-bc55-2153ca23b11d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9HvxlF5IS5d",
    "outputId": "0b8acbee-3cf6-47fa-ef79-7d908ea40ef2"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "try:\n",
    "    if \"cleaned_text\" not in df.columns and \"clean_text\" in df.columns:\n",
    "        df = df.withColumnRenamed(\"clean_text\", \"cleaned_text\")\n",
    "\n",
    "except AttributeError:\n",
    "    raise TypeError(\"df is not a Spark DataFrame\")\n",
    "\n",
    "\n",
    "\n",
    "REQUIRED_COL = \"cleaned_text\"\n",
    "\n",
    "\n",
    "def validate_input_data(df):\n",
    "\n",
    "    if REQUIRED_COL not in df.columns:\n",
    "        raise ValueError(f\"Missing column: {REQUIRED_COL}\")\n",
    "\n",
    "\n",
    "    if df.rdd.isEmpty():\n",
    "        raise ValueError(\" DataFrame is empty\")\n",
    "\n",
    "\n",
    "    null_count = df.filter(col(REQUIRED_COL).isNull()).count()\n",
    "    if null_count > 0:\n",
    "        print(f\" {null_count} null rows dropped\")\n",
    "\n",
    "    return df.filter(col(REQUIRED_COL).isNotNull())\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    df = validate_input_data(df)\n",
    "\n",
    "except ValueError as e:\n",
    "    raise ValueError(e)\n",
    "\n",
    "except Exception:\n",
    "    raise RuntimeError(\" Spark job failed during validation\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    df.select(\"cleaned_text\").show(5, truncate=False)\n",
    "except Exception:\n",
    "    raise RuntimeError(\"‚ùå Unable to show DataFrame (Spark issue)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3881fd8-65cc-42c8-b943-82a4265467dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8NfmEaGzGf68",
    "outputId": "bc8da66e-90e1-4816-bddd-10e9e55a8ec1"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# NLP Components\n",
    "# ================================\n",
    "try:\n",
    "    document_assembler = DocumentAssembler() \\\n",
    "        .setInputCol(\"clean_text\") \\\n",
    "        .setOutputCol(\"document\")\n",
    "\n",
    "    tokenizer = Tokenizer() \\\n",
    "        .setInputCols([\"document\"]) \\\n",
    "        .setOutputCol(\"token\")\n",
    "\n",
    "    embeddings = UniversalSentenceEncoder.pretrained(\n",
    "        \"tfhub_use\", \"en\"\n",
    "    ).setInputCols([\"document\"]) \\\n",
    "     .setOutputCol(\"embeddings\")\n",
    "\n",
    "    sentiment_model = SentimentDLModel.pretrained(\n",
    "        \"sentimentdl_use_twitter\", \"en\"\n",
    "    ).setInputCols([\"embeddings\"]) \\\n",
    "     .setOutputCol(\"sentiment\")\n",
    "\n",
    "    print(\"NLP components initialized\")\n",
    "\n",
    "except AttributeError:\n",
    "    raise RuntimeError(\"Spark NLP not initialized or Spark session missing\")\n",
    "\n",
    "except ValueError:\n",
    "    raise RuntimeError(\"Invalid input or output column configuration\")\n",
    "\n",
    "except Exception as e:\n",
    "    if \"Model not found\" in str(e):\n",
    "        raise RuntimeError(\"Pretrained model not available or download failed\")\n",
    "    elif \"No such file or directory\" in str(e):\n",
    "        raise RuntimeError(\"Spark NLP cache or filesystem issue\")\n",
    "    elif \"Java gateway process exited\" in str(e):\n",
    "        raise RuntimeError(\"JVM or Java version issue\")\n",
    "    else:\n",
    "        raise RuntimeError(\"NLP component initialization failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dcd6d4b-4817-4d29-ba4e-91bb47df9bf7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EIP2Sh9YOmvr"
   },
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed(\"cleaned_text\", \"clean_text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef7c9a60-2862-443b-831b-6e05edab03a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XgowA0MaGtIP",
    "outputId": "ffede0e3-e7d4-415c-a337-fae71d3ef6e5"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Run Prediction\n",
    "# ================================\n",
    "try:\n",
    "    model = pipeline.fit(df)\n",
    "    prediction_df = model.transform(df)\n",
    "\n",
    "    print(\"Sentiment prediction completed\")\n",
    "\n",
    "except ValueError:\n",
    "    raise RuntimeError(\"Invalid pipeline configuration or input data\")\n",
    "\n",
    "except AttributeError:\n",
    "    raise RuntimeError(\"Pipeline or DataFrame not initialized\")\n",
    "\n",
    "except Exception as e:\n",
    "    if \"Job aborted\" in str(e):\n",
    "        raise RuntimeError(\"Spark job failed during model execution\")\n",
    "    elif \"OutOfMemoryError\" in str(e):\n",
    "        raise RuntimeError(\"Insufficient memory during prediction\")\n",
    "    elif \"AnalysisException\" in str(e):\n",
    "        raise RuntimeError(\"Schema or column mismatch during prediction\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Prediction step failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f867653b-69bb-4a93-b020-a8602361e05c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHupzYDxG-62",
    "outputId": "86c68e50-da03-4a8e-f2dd-d5137666c844"
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Extract Sentiment Label\n",
    "# ================================\n",
    "try:\n",
    "    final_df = (\n",
    "        prediction_df\n",
    "        .withColumn(\"sentiment_label\", col(\"sentiment\")[0][\"result\"])\n",
    "        .withColumn(\"_prediction_timestamp\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    final_df.select(\n",
    "        \"clean_text\",\n",
    "        \"sentiment_label\"\n",
    "    ).show(10, truncate=False)\n",
    "\n",
    "    print(\"Sentiment label extracted\")\n",
    "\n",
    "except AttributeError:\n",
    "    raise RuntimeError(\"Prediction DataFrame not available\")\n",
    "\n",
    "except IndexError:\n",
    "    raise RuntimeError(\"Sentiment result is empty or missing\")\n",
    "\n",
    "except Exception as e:\n",
    "    if \"AnalysisException\" in str(e):\n",
    "        raise RuntimeError(\"Sentiment column structure mismatch\")\n",
    "    elif \"Job aborted\" in str(e):\n",
    "        raise RuntimeError(\"Spark job failed during sentiment extraction\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Sentiment extraction failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6f392de-82fc-46d6-bfbe-29693586b462",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_nSN14BKrXV",
    "outputId": "b325a511-fdd2-4fb1-8c1b-a12971c279f6"
   },
   "outputs": [],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c411ca89-857b-4e67-8eb9-cb91251dff66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jENo4OzVHAT6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Writing the csv file\n",
    "\n",
    "try:\n",
    "    final_df \\\n",
    "        .select(\"clean_text\", \"sentiment_label\") \\\n",
    "        .coalesce(1) \\\n",
    "        .write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(\"/content/final_ml_predictions\")\n",
    "\n",
    "    print(\"‚úÖ CSV written successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"‚ùå CSV write failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff9e1cfd-07c7-4bce-9ad7-48f59870afb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dOoZmNarb3S",
    "outputId": "4ec81c55-ce0d-4856-96fb-28a9e841810b"
   },
   "outputs": [],
   "source": [
    "final_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4654e8e-aeee-4102-b447-dfc97c2cdb92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gomy__5aMJj5",
    "outputId": "b087361d-e3f3-4212-b4ad-a03ac29a4d8b"
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "print(f\"Total runtime: {round(end_time - start_time, 2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ml_flow_notebook",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
