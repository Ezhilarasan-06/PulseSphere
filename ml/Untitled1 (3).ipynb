{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "1pFxorg8Mz5U"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiWLFVIKE9_U",
        "outputId": "09421133-c37c-42c9-bc0b-75ec48af30c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.4.1 in /usr/local/lib/python3.12/dist-packages (3.4.1)\n",
            "Requirement already satisfied: spark-nlp==5.4.0 in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyspark==3.4.1 spark-nlp==5.4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Spark NLP Initialization\n",
        "\n",
        "try:\n",
        "    import sparknlp\n",
        "    spark = sparknlp.start()\n",
        "    print(\"‚úÖ Spark NLP started successfully\")\n",
        "\n",
        "except ModuleNotFoundError as e:\n",
        "    raise ModuleNotFoundError(\n",
        "        \"‚ùå Spark NLP not found.\\n\"\n",
        "        \"üëâ Run: pip install spark-nlp\\n\"\n",
        "        \"üëâ Restart runtime after install.\"\n",
        "    ) from e\n",
        "\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"Spark Connect server and Spark master cannot be configured together\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark Connect conflict detected.\\n\"\n",
        "            \"üëâ Do NOT call sparknlp.start() in Databricks.\\n\"\n",
        "            \"üëâ Use existing SparkSession instead.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Java gateway process exited\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Java/JVM failed to start.\\n\"\n",
        "            \"üëâ Ensure Java 8 or 11 is installed.\\n\"\n",
        "            \"üëâ Restart the runtime.\"\n",
        "        ) from e\n",
        "\n",
        "\n",
        "    elif \"spark.jsl.settings.pretrained.cache_folder\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark NLP cache configuration error.\\n\"\n",
        "            \"üëâ Do NOT set spark.jsl.settings.pretrained.cache_folder manually.\\n\"\n",
        "            \"üëâ Use environment variable SPARK_NLP_CACHE instead.\"\n",
        "        ) from e\n",
        "\n",
        "\n",
        "    elif \"OutOfMemoryError\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Out of Memory error.\\n\"\n",
        "            \"üëâ Reduce batch size or increase driver memory.\"\n",
        "        ) from e\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(f\"‚ùå Spark NLP init failed: {e}\") from e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUmAa0RUFSFl",
        "outputId": "f95139f9-2911-4f7d-bc0c-06f06e041872"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "‚úÖ Spark NLP started successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.annotator import ClassifierDLModel\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n"
      ],
      "metadata": {
        "id": "k6fwoUZzL2CM"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "try:\n",
        "    from sparknlp.base import DocumentAssembler\n",
        "    from sparknlp.annotator import (\n",
        "        Tokenizer,\n",
        "        UniversalSentenceEncoder,\n",
        "        SentimentDLModel\n",
        "    )\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.sql.functions import col, current_timestamp\n",
        "\n",
        "    print(\"‚úÖ Imports successful\")\n",
        "\n",
        "except ModuleNotFoundError as e:\n",
        "    if \"sparknlp\" in str(e):\n",
        "        raise ModuleNotFoundError(\n",
        "            \"‚ùå Spark NLP not installed.\\n\"\n",
        "            \"üëâ Fix: pip install spark-nlp\\n\"\n",
        "            \"üëâ Restart runtime after installation.\"\n",
        "        ) from e\n",
        "    elif \"pyspark\" in str(e):\n",
        "        raise ModuleNotFoundError(\n",
        "            \"‚ùå PySpark not installed.\\n\"\n",
        "            \"üëâ Fix: pip install pyspark\\n\"\n",
        "            \"üëâ Restart runtime.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "\n",
        "except ImportError as e:\n",
        "    if \"UniversalSentenceEncoder\" in str(e):\n",
        "        raise ImportError(\n",
        "            \"‚ùå UniversalSentenceEncoder not available.\\n\"\n",
        "            \"üëâ Spark NLP version too old.\\n\"\n",
        "            \"üëâ Upgrade: pip install --upgrade spark-nlp\"\n",
        "        ) from e\n",
        "    elif \"SentimentDLModel\" in str(e):\n",
        "        raise ImportError(\n",
        "            \"‚ùå SentimentDLModel not found.\\n\"\n",
        "            \"üëâ Spark NLP ML annotators not available in this version.\\n\"\n",
        "            \"üëâ Upgrade Spark NLP.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "except Exception as e:\n",
        "    if \"JavaPackage\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark NLP JVM classes not loaded.\\n\"\n",
        "            \"üëâ Spark session not initialized correctly.\\n\"\n",
        "            \"üëâ Ensure sparknlp.start() ran successfully.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise RuntimeError(f\"‚ùå Import failed: {e}\") from e\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIXmmRAnFYpj",
        "outputId": "4b70563f-71a6-4bf9-93a1-1374c874a24a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .csv(\"/content/sliver_layer__1_ (1).csv\")\n",
        ")"
      ],
      "metadata": {
        "id": "XC_IGw1IGNit"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWgiHYcjJGlx",
        "outputId": "5cad6a3b-9fd7-40f2-e7c6-4ddbf7270dde"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "try:\n",
        "    if \"cleaned_text\" not in df.columns and \"clean_text\" in df.columns:\n",
        "        df = df.withColumnRenamed(\"clean_text\", \"cleaned_text\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise TypeError(\"df is not a Spark DataFrame\")\n",
        "\n",
        "\n",
        "\n",
        "REQUIRED_COL = \"cleaned_text\"\n",
        "\n",
        "\n",
        "def validate_input_data(df):\n",
        "\n",
        "    if REQUIRED_COL not in df.columns:\n",
        "        raise ValueError(f\"Missing column: {REQUIRED_COL}\")\n",
        "\n",
        "\n",
        "    if df.rdd.isEmpty():\n",
        "        raise ValueError(\" DataFrame is empty\")\n",
        "\n",
        "\n",
        "    null_count = df.filter(col(REQUIRED_COL).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        print(f\" {null_count} null rows dropped\")\n",
        "\n",
        "    return df.filter(col(REQUIRED_COL).isNotNull())\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    df = validate_input_data(df)\n",
        "\n",
        "except ValueError as e:\n",
        "    raise ValueError(e)\n",
        "\n",
        "except Exception:\n",
        "    raise RuntimeError(\" Spark job failed during validation\")\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    df.select(\"cleaned_text\").show(5, truncate=False)\n",
        "except Exception:\n",
        "    raise RuntimeError(\"‚ùå Unable to show DataFrame (Spark issue)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9HvxlF5IS5d",
        "outputId": "0b8acbee-3cf6-47fa-ef79-7d908ea40ef2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|cleaned_text                                                                                                                                           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# NLP Components\n",
        "# ================================\n",
        "try:\n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"clean_text\") \\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"document\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    embeddings = UniversalSentenceEncoder.pretrained(\n",
        "        \"tfhub_use\", \"en\"\n",
        "    ).setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"embeddings\")\n",
        "\n",
        "    sentiment_model = SentimentDLModel.pretrained(\n",
        "        \"sentimentdl_use_twitter\", \"en\"\n",
        "    ).setInputCols([\"embeddings\"]) \\\n",
        "     .setOutputCol(\"sentiment\")\n",
        "\n",
        "    print(\"NLP components initialized\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Spark NLP not initialized or Spark session missing\")\n",
        "\n",
        "except ValueError:\n",
        "    raise RuntimeError(\"Invalid input or output column configuration\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Model not found\" in str(e):\n",
        "        raise RuntimeError(\"Pretrained model not available or download failed\")\n",
        "    elif \"No such file or directory\" in str(e):\n",
        "        raise RuntimeError(\"Spark NLP cache or filesystem issue\")\n",
        "    elif \"Java gateway process exited\" in str(e):\n",
        "        raise RuntimeError(\"JVM or Java version issue\")\n",
        "    else:\n",
        "        raise RuntimeError(\"NLP component initialization failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfmEaGzGf68",
        "outputId": "bc8da66e-90e1-4816-bddd-10e9e55a8ec1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n",
            "NLP components initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# NLP Components\n",
        "# ================================\n",
        "try:\n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"clean_text\") \\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"document\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    embeddings = UniversalSentenceEncoder.pretrained(\n",
        "        \"tfhub_use\", \"en\"\n",
        "    ).setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"embeddings\")\n",
        "\n",
        "    sentiment_model = SentimentDLModel.pretrained(\n",
        "        \"sentimentdl_use_twitter\", \"en\"\n",
        "    ).setInputCols([\"embeddings\"]) \\\n",
        "     .setOutputCol(\"sentiment\")\n",
        "\n",
        "    print(\"NLP components initialized\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Spark NLP or Spark session not available\")\n",
        "\n",
        "except ValueError:\n",
        "    raise RuntimeError(\"Invalid input or output column configuration\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Model not found\" in str(e):\n",
        "        raise RuntimeError(\"Pretrained model unavailable or download failed\")\n",
        "    elif \"No such file or directory\" in str(e):\n",
        "        raise RuntimeError(\"Spark NLP cache or filesystem problem\")\n",
        "    elif \"Java gateway process exited\" in str(e):\n",
        "        raise RuntimeError(\"Java or JVM configuration issue\")\n",
        "    else:\n",
        "        raise RuntimeError(\"NLP component initialization failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMlKz2RiGo8o",
        "outputId": "d46af70a-6368-4320-c344-004405ec5cc8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n",
            "NLP components initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed(\"cleaned_text\", \"clean_text\")\n"
      ],
      "metadata": {
        "id": "EIP2Sh9YOmvr"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Run Prediction\n",
        "# ================================\n",
        "try:\n",
        "    model = pipeline.fit(df)\n",
        "    prediction_df = model.transform(df)\n",
        "\n",
        "    print(\"Sentiment prediction completed\")\n",
        "\n",
        "except ValueError:\n",
        "    raise RuntimeError(\"Invalid pipeline configuration or input data\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Pipeline or DataFrame not initialized\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Job aborted\" in str(e):\n",
        "        raise RuntimeError(\"Spark job failed during model execution\")\n",
        "    elif \"OutOfMemoryError\" in str(e):\n",
        "        raise RuntimeError(\"Insufficient memory during prediction\")\n",
        "    elif \"AnalysisException\" in str(e):\n",
        "        raise RuntimeError(\"Schema or column mismatch during prediction\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Prediction step failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgowA0MaGtIP",
        "outputId": "ffede0e3-e7d4-415c-a337-fae71d3ef6e5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Extract Sentiment Label\n",
        "# ================================\n",
        "try:\n",
        "    final_df = (\n",
        "        prediction_df\n",
        "        .withColumn(\"sentiment_label\", col(\"sentiment\")[0][\"result\"])\n",
        "        .withColumn(\"_prediction_timestamp\", current_timestamp())\n",
        "    )\n",
        "\n",
        "    final_df.select(\n",
        "        \"clean_text\",\n",
        "        \"sentiment_label\"\n",
        "    ).show(10, truncate=False)\n",
        "\n",
        "    print(\"Sentiment label extracted\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Prediction DataFrame not available\")\n",
        "\n",
        "except IndexError:\n",
        "    raise RuntimeError(\"Sentiment result is empty or missing\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"AnalysisException\" in str(e):\n",
        "        raise RuntimeError(\"Sentiment column structure mismatch\")\n",
        "    elif \"Job aborted\" in str(e):\n",
        "        raise RuntimeError(\"Spark job failed during sentiment extraction\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Sentiment extraction failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHupzYDxG-62",
        "outputId": "86c68e50-da03-4a8e-f2dd-d5137666c844"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|clean_text                                                                                                                                             |sentiment_label|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |positive       |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |positive       |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |positive       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |positive       |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|positive       |\n",
            "|edge network wall quite boy those seem shoulder future fall citizen about mfa teresa harrellkenneth                                                    |positive       |\n",
            "|patch for credential stuffing vulnerability released upon these story film soc allenashley millertodd                                                  |negative       |\n",
            "|campaign little near enter their institution deep hacking phishing soc jenniferross samuel                                                             |negative       |\n",
            "|according remain arrive attack all form method everything democrat car very number line six space cve clintonhopkins rodney                            |positive       |\n",
            "|backup systems engaged after brute force eat couple large instead cybersecurity mfa mfa steven williamsyvette                                          |positive       |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Sentiment label extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Extract Sentiment Label\n",
        "# ================================\n",
        "try:\n",
        "    final_df = (\n",
        "        prediction_df\n",
        "        .withColumn(\"sentiment_label\", col(\"sentiment\")[0][\"result\"])\n",
        "        .withColumn(\"_prediction_timestamp\", current_timestamp())\n",
        "    )\n",
        "\n",
        "    final_df.select(\n",
        "        \"clean_text\",\n",
        "        \"sentiment_label\"\n",
        "    ).show(10, truncate=False)\n",
        "\n",
        "    print(\"Sentiment label extracted\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Prediction DataFrame not available\")\n",
        "\n",
        "except IndexError:\n",
        "    raise RuntimeError(\"Sentiment output is empty or missing\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"AnalysisException\" in str(e):\n",
        "        raise RuntimeError(\"Sentiment column schema mismatch\")\n",
        "    elif \"Job aborted\" in str(e):\n",
        "        raise RuntimeError(\"Spark execution failed during extraction\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Sentiment extraction failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCSORRCRONHF",
        "outputId": "c3ae267d-104a-44ba-cf25-92b09e362c34"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|clean_text                                                                                                                                             |sentiment_label|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |positive       |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |positive       |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |positive       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |positive       |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|positive       |\n",
            "|edge network wall quite boy those seem shoulder future fall citizen about mfa teresa harrellkenneth                                                    |positive       |\n",
            "|patch for credential stuffing vulnerability released upon these story film soc allenashley millertodd                                                  |negative       |\n",
            "|campaign little near enter their institution deep hacking phishing soc jenniferross samuel                                                             |negative       |\n",
            "|according remain arrive attack all form method everything democrat car very number line six space cve clintonhopkins rodney                            |positive       |\n",
            "|backup systems engaged after brute force eat couple large instead cybersecurity mfa mfa steven williamsyvette                                          |positive       |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Sentiment label extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion Pipeline\n",
        "\n",
        "emotion_pipeline = Pipeline(stages=[\n",
        "    emotion_model\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Emotion pipeline created\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDnJN55TOS9g",
        "outputId": "b259a0ac-dac8-4961-9c0b-9e28f46f930d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Emotion pipeline created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Run Emotion Prediction\n",
        "emotion_predictions = emotion_pipeline.fit(final_df).transform(final_df)\n",
        "\n",
        "print(\"‚úÖ Emotion prediction completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hq_uXOPSTso",
        "outputId": "b4ba1734-237b-4b7f-f599-bdbfc8075030"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Emotion prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extract Emotion Label\n",
        "\n",
        "final_df = emotion_predictions.withColumn(\n",
        "    \"emotion_label\",\n",
        "    col(\"emotion\")[0][\"result\"]\n",
        ")\n",
        "\n",
        "final_df.select(\"clean_text\",\"emotion_label\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSzwSnXVSY-k",
        "outputId": "1ef676c2-3e7a-4206-ddd5-2d906b1814c4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
            "|clean_text                                                                                                                                             |emotion_label|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |joy          |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |fear         |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |fear         |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |fear         |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|fear         |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_nSN14BKrXV",
        "outputId": "b325a511-fdd2-4fb1-8c1b-a12971c279f6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment_label: string (nullable = true)\n",
            " |-- _prediction_timestamp: timestamp (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Writing the csv file\n",
        "\n",
        "try:\n",
        "    final_df \\\n",
        "        .select(\"clean_text\", \"sentiment_label\") \\\n",
        "        .coalesce(1) \\\n",
        "        .write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .csv(\"/content/final_ml_predictions\")\n",
        "\n",
        "    print(\"‚úÖ CSV written successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"‚ùå CSV write failed: {e}\")\n"
      ],
      "metadata": {
        "id": "jENo4OzVHAT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOoZmNarb3S",
        "outputId": "4ec81c55-ce0d-4856-96fb-28a9e841810b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "503456"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "\n",
        "print(f\"Total runtime: {round(end_time - start_time, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomy__5aMJj5",
        "outputId": "b087361d-e3f3-4212-b4ad-a03ac29a4d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total runtime: 1490.08 seconds\n"
          ]
        }
      ]
    }
  ]
}