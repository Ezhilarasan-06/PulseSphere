{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "1pFxorg8Mz5U"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiWLFVIKE9_U",
        "outputId": "875460ce-6878-4969-e37b-d062f10a3178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark==3.4.1 in /usr/local/lib/python3.12/dist-packages (3.4.1)\n",
            "Requirement already satisfied: spark-nlp==5.4.0 in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark==3.4.1) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyspark==3.4.1 spark-nlp==5.4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUmAa0RUFSFl",
        "outputId": "a2ad175f-7900-427e-bff5-015c7103074a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning::Spark Session already created, some configs may not take.\n",
            "‚úÖ Spark NLP started successfully\n"
          ]
        }
      ],
      "source": [
        " #Spark NLP Initialization\n",
        "\n",
        "try:\n",
        "    import sparknlp\n",
        "    spark = sparknlp.start()\n",
        "    print(\"‚úÖ Spark NLP started successfully\")\n",
        "\n",
        "except ModuleNotFoundError as e:\n",
        "    raise ModuleNotFoundError(\n",
        "        \"‚ùå Spark NLP not found.\\n\"\n",
        "        \"üëâ Run: pip install spark-nlp\\n\"\n",
        "        \"üëâ Restart runtime after install.\"\n",
        "    ) from e\n",
        "\n",
        "\n",
        "except RuntimeError as e:\n",
        "    if \"Spark Connect server and Spark master cannot be configured together\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark Connect conflict detected.\\n\"\n",
        "            \"üëâ Do NOT call sparknlp.start() in Databricks.\\n\"\n",
        "            \"üëâ Use existing SparkSession instead.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Java gateway process exited\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Java/JVM failed to start.\\n\"\n",
        "            \"üëâ Ensure Java 8 or 11 is installed.\\n\"\n",
        "            \"üëâ Restart the runtime.\"\n",
        "        ) from e\n",
        "\n",
        "\n",
        "    elif \"spark.jsl.settings.pretrained.cache_folder\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark NLP cache configuration error.\\n\"\n",
        "            \"üëâ Do NOT set spark.jsl.settings.pretrained.cache_folder manually.\\n\"\n",
        "            \"üëâ Use environment variable SPARK_NLP_CACHE instead.\"\n",
        "        ) from e\n",
        "\n",
        "\n",
        "    elif \"OutOfMemoryError\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Out of Memory error.\\n\"\n",
        "            \"üëâ Reduce batch size or increase driver memory.\"\n",
        "        ) from e\n",
        "\n",
        "    else:\n",
        "        raise RuntimeError(f\"‚ùå Spark NLP init failed: {e}\") from e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "k6fwoUZzL2CM"
      },
      "outputs": [],
      "source": [
        "from sparknlp.annotator import ClassifierDLModel\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIXmmRAnFYpj",
        "outputId": "090c4b54-63ea-44f3-ac86-b15c6c55610a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Imports successful\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "try:\n",
        "    from sparknlp.base import DocumentAssembler\n",
        "    from sparknlp.annotator import (\n",
        "        Tokenizer,\n",
        "        UniversalSentenceEncoder,\n",
        "        SentimentDLModel\n",
        "    )\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.sql.functions import col, current_timestamp\n",
        "\n",
        "    print(\"‚úÖ Imports successful\")\n",
        "\n",
        "except ModuleNotFoundError as e:\n",
        "    if \"sparknlp\" in str(e):\n",
        "        raise ModuleNotFoundError(\n",
        "            \"‚ùå Spark NLP not installed.\\n\"\n",
        "            \"üëâ Fix: pip install spark-nlp\\n\"\n",
        "            \"üëâ Restart runtime after installation.\"\n",
        "        ) from e\n",
        "    elif \"pyspark\" in str(e):\n",
        "        raise ModuleNotFoundError(\n",
        "            \"‚ùå PySpark not installed.\\n\"\n",
        "            \"üëâ Fix: pip install pyspark\\n\"\n",
        "            \"üëâ Restart runtime.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "\n",
        "except ImportError as e:\n",
        "    if \"UniversalSentenceEncoder\" in str(e):\n",
        "        raise ImportError(\n",
        "            \"‚ùå UniversalSentenceEncoder not available.\\n\"\n",
        "            \"üëâ Spark NLP version too old.\\n\"\n",
        "            \"üëâ Upgrade: pip install --upgrade spark-nlp\"\n",
        "        ) from e\n",
        "    elif \"SentimentDLModel\" in str(e):\n",
        "        raise ImportError(\n",
        "            \"‚ùå SentimentDLModel not found.\\n\"\n",
        "            \"üëâ Spark NLP ML annotators not available in this version.\\n\"\n",
        "            \"üëâ Upgrade Spark NLP.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise\n",
        "\n",
        "except Exception as e:\n",
        "    if \"JavaPackage\" in str(e):\n",
        "        raise RuntimeError(\n",
        "            \"‚ùå Spark NLP JVM classes not loaded.\\n\"\n",
        "            \"üëâ Spark session not initialized correctly.\\n\"\n",
        "            \"üëâ Ensure sparknlp.start() ran successfully.\"\n",
        "        ) from e\n",
        "    else:\n",
        "        raise RuntimeError(f\"‚ùå Import failed: {e}\") from e\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XC_IGw1IGNit"
      },
      "outputs": [],
      "source": [
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .csv(\"/content/sliver_layer__1_ (1).csv\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWgiHYcjJGlx",
        "outputId": "ccfd8e1d-ae26-4d34-8af8-677cb5426b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9HvxlF5IS5d",
        "outputId": "99a0ead9-3081-4330-eeaa-a709391e7a03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|cleaned_text                                                                                                                                           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "try:\n",
        "    if \"cleaned_text\" not in df.columns and \"clean_text\" in df.columns:\n",
        "        df = df.withColumnRenamed(\"clean_text\", \"cleaned_text\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise TypeError(\"df is not a Spark DataFrame\")\n",
        "\n",
        "\n",
        "\n",
        "REQUIRED_COL = \"cleaned_text\"\n",
        "\n",
        "\n",
        "def validate_input_data(df):\n",
        "\n",
        "    if REQUIRED_COL not in df.columns:\n",
        "        raise ValueError(f\"Missing column: {REQUIRED_COL}\")\n",
        "\n",
        "\n",
        "    if df.rdd.isEmpty():\n",
        "        raise ValueError(\" DataFrame is empty\")\n",
        "\n",
        "\n",
        "    null_count = df.filter(col(REQUIRED_COL).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        print(f\" {null_count} null rows dropped\")\n",
        "\n",
        "    return df.filter(col(REQUIRED_COL).isNotNull())\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    df = validate_input_data(df)\n",
        "\n",
        "except ValueError as e:\n",
        "    raise ValueError(e)\n",
        "\n",
        "except Exception:\n",
        "    raise RuntimeError(\" Spark job failed during validation\")\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    df.select(\"cleaned_text\").show(5, truncate=False)\n",
        "except Exception:\n",
        "    raise RuntimeError(\"‚ùå Unable to show DataFrame (Spark issue)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfmEaGzGf68",
        "outputId": "3ec489ad-d059-463e-a87c-51a56440f117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n",
            "NLP components initialized\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# NLP Components\n",
        "# ================================\n",
        "try:\n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"clean_text\") \\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"document\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    embeddings = UniversalSentenceEncoder.pretrained(\n",
        "        \"tfhub_use\", \"en\"\n",
        "    ).setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"embeddings\")\n",
        "\n",
        "    sentiment_model = SentimentDLModel.pretrained(\n",
        "        \"sentimentdl_use_twitter\", \"en\"\n",
        "    ).setInputCols([\"embeddings\"]) \\\n",
        "     .setOutputCol(\"sentiment\")\n",
        "\n",
        "    print(\"NLP components initialized\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Spark NLP not initialized or Spark session missing\")\n",
        "\n",
        "except ValueError:\n",
        "    raise RuntimeError(\"Invalid input or output column configuration\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Model not found\" in str(e):\n",
        "        raise RuntimeError(\"Pretrained model not available or download failed\")\n",
        "    elif \"No such file or directory\" in str(e):\n",
        "        raise RuntimeError(\"Spark NLP cache or filesystem issue\")\n",
        "    elif \"Java gateway process exited\" in str(e):\n",
        "        raise RuntimeError(\"JVM or Java version issue\")\n",
        "    else:\n",
        "        raise RuntimeError(\"NLP component initialization failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "EIP2Sh9YOmvr"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"cleaned_text\", \"clean_text\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3VO7KQeWLxLx"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    embeddings,\n",
        "    sentiment_model\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIad9ALGRfAH",
        "outputId": "017f2b54-52da-46b0-b4d4-d52a8054c5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "iCOVDPOAUri6"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"cleaned_text\") \\\n",
        "    .setOutputCol(\"document\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAAKdNjsjlEW",
        "outputId": "53479a2b-2db9-405a-fcad-b0f619a82d19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['id',\n",
              " 'text',\n",
              " 'created_at',\n",
              " 'username',\n",
              " 'user_id',\n",
              " 'language',\n",
              " 'retweet_count',\n",
              " 'like_count',\n",
              " 'reply_count',\n",
              " 'quote_count',\n",
              " 'impression_count',\n",
              " 'hashtags',\n",
              " 'mentions',\n",
              " 'source',\n",
              " 'is_retweet',\n",
              " 'is_reply',\n",
              " 'in_reply_to_user_id',\n",
              " 'conversation_id',\n",
              " 'user_followers_count',\n",
              " 'user_following_count',\n",
              " 'user_verified',\n",
              " 'user_location',\n",
              " 'possibly_sensitive',\n",
              " 'ingestion_time',\n",
              " 'clean_text',\n",
              " 'is_reply_flag']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "nlp_cols = [\n",
        "    \"document\",\n",
        "    \"token\",\n",
        "    \"embeddings\",\n",
        "    \"sentiment\",\n",
        "    \"sentiment_label\",\n",
        "    \"_prediction_timestamp\"\n",
        "]\n",
        "\n",
        "base_df = df.drop(*[c for c in nlp_cols if c in df.columns])\n",
        "base_df.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "j6eEATtzU41G"
      },
      "outputs": [],
      "source": [
        "model = pipeline.fit(base_df)\n",
        "prediction_df = model.transform(base_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgowA0MaGtIP",
        "outputId": "91e218d9-05db-4072-fb48-4c573453da04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment prediction completed\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# Run Prediction\n",
        "# ================================\n",
        "try:\n",
        "    model = pipeline.fit(base_df)\n",
        "    prediction_df = model.transform(base_df)\n",
        "\n",
        "    print(\"Sentiment prediction completed\")\n",
        "\n",
        "except ValueError:\n",
        "    raise RuntimeError(\"Invalid pipeline configuration or input data\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"Pipeline or DataFrame not initialized\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"Job aborted\" in str(e):\n",
        "        raise RuntimeError(\"Spark job failed during model execution\")\n",
        "    elif \"OutOfMemoryError\" in str(e):\n",
        "        raise RuntimeError(\"Insufficient memory during prediction\")\n",
        "    elif \"AnalysisException\" in str(e):\n",
        "        raise RuntimeError(\"Schema or column mismatch during prediction\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Prediction step failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5owYD00qVbQr",
        "outputId": "78200b4a-0071-409f-d4d6-0d897e259e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|clean_text                                                                                                                                             |sentiment_label|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |positive       |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |positive       |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |positive       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |positive       |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|positive       |\n",
            "|edge network wall quite boy those seem shoulder future fall citizen about mfa teresa harrellkenneth                                                    |positive       |\n",
            "|patch for credential stuffing vulnerability released upon these story film soc allenashley millertodd                                                  |negative       |\n",
            "|campaign little near enter their institution deep hacking phishing soc jenniferross samuel                                                             |negative       |\n",
            "|according remain arrive attack all form method everything democrat car very number line six space cve clintonhopkins rodney                            |positive       |\n",
            "|backup systems engaged after brute force eat couple large instead cybersecurity mfa mfa steven williamsyvette                                          |positive       |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "‚úÖ Sentiment label extracted successfully\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, current_timestamp\n",
        "\n",
        "# ================================\n",
        "# Extract Sentiment Label (FIXED)\n",
        "# ================================\n",
        "try:\n",
        "    df = (\n",
        "        prediction_df\n",
        "        .withColumn(\"sentiment_label\", col(\"sentiment\")[0][\"result\"])\n",
        "        .withColumn(\"_prediction_timestamp\", current_timestamp())\n",
        "    )\n",
        "\n",
        "    df.select(\n",
        "        \"clean_text\",\n",
        "        \"sentiment_label\"\n",
        "    ).show(10, truncate=False)\n",
        "\n",
        "    print(\"‚úÖ Sentiment label extracted successfully\")\n",
        "\n",
        "except AttributeError:\n",
        "    raise RuntimeError(\"‚ùå Prediction DataFrame not available\")\n",
        "\n",
        "except IndexError:\n",
        "    raise RuntimeError(\"‚ùå Sentiment result is empty or missing\")\n",
        "\n",
        "except Exception as e:\n",
        "    if \"UNRESOLVED_COLUMN\" in str(e):\n",
        "        raise RuntimeError(\"‚ùå Column name mismatch (check clean_text)\")\n",
        "    elif \"Job aborted\" in str(e):\n",
        "        raise RuntimeError(\"‚ùå Spark job failed during sentiment extraction\")\n",
        "    else:\n",
        "        raise RuntimeError(f\"‚ùå Sentiment extraction failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_nSN14BKrXV",
        "outputId": "a3f2ac81-0ebd-44ad-d421-8fa325d5c5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment_label: string (nullable = true)\n",
            " |-- _prediction_timestamp: timestamp (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparknlp.base import DocumentAssembler\n",
        "from sparknlp.annotator import (\n",
        "    Tokenizer,\n",
        "    UniversalSentenceEncoder,\n",
        "    ClassifierDLModel\n",
        ")\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import col\n"
      ],
      "metadata": {
        "id": "DOl2VSCVY1ct"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = (\n",
        "    DocumentAssembler()\n",
        "    .setInputCol(\"clean_text\")\n",
        "    .setOutputCol(\"document\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "zkbfM4kqY2Ce"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = (\n",
        "    Tokenizer()\n",
        "    .setInputCols([\"document\"])\n",
        "    .setOutputCol(\"token\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "oPKmdaYDY497"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = (\n",
        "    UniversalSentenceEncoder.pretrained(\n",
        "        \"tfhub_use\",\n",
        "        \"en\"\n",
        "    )\n",
        "    .setInputCols([\"document\"])\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlBCLL7BY7ck",
        "outputId": "a390f040-bb4e-4005-b184-dbea106f6af2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model = (\n",
        "    ClassifierDLModel.pretrained(\n",
        "        \"classifierdl_use_emotion\",\n",
        "        \"en\"\n",
        "    )\n",
        "    .setInputCols([\"sentence_embeddings\"])\n",
        "    .setOutputCol(\"emotion\")\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krfbRNraY_zg",
        "outputId": "9749cc14-d665-42ad-c0ae-01b9af6d85f1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classifierdl_use_emotion download started this may take some time.\n",
            "Approximate size to download 21.3 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_pipeline = Pipeline(stages=[\n",
        "    document_assembler,\n",
        "    tokenizer,\n",
        "    embeddings,\n",
        "    emotion_model\n",
        "])\n"
      ],
      "metadata": {
        "id": "JTO5yPLNZJbe"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df = emotion_pipeline.fit(df).transform(df)\n"
      ],
      "metadata": {
        "id": "QNax7dxVZNVu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "emotion_df = emotion_df.withColumn(\n",
        "    \"emotion_label\",\n",
        "    col(\"emotion\")[0][\"result\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "-hTz5WNcZoR8"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df = emotion_df.withColumn(\n",
        "    \"emotion_confidence\",\n",
        "    col(\"emotion\")[0][\"metadata\"].getItem(\"confidence\").cast(\"double\")\n",
        ")\n"
      ],
      "metadata": {
        "id": "vmSJB18bZuf-"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijyhFi0gZc4z",
        "outputId": "facd4f63-7544-4ec1-a226-59d5ae84c8da"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment_label: string (nullable = true)\n",
            " |-- _prediction_timestamp: timestamp (nullable = false)\n",
            " |-- sentence_embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- emotion: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- emotion_label: string (nullable = true)\n",
            " |-- emotion_confidence: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df.select(\n",
        "    \"clean_text\",\n",
        "    \"emotion_label\",\n",
        "    \"emotion_confidence\"\n",
        ").show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PCV1b1_ZRY7",
        "outputId": "711d5b51-44cf-4e0f-c762-7ac2e54ea53b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------+\n",
            "|clean_text                                                                                                                                                     |emotion_label|emotion_confidence|\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                            |joy          |null              |\n",
            "|night respond red information last everything cve blakeerik                                                                                                    |fear         |null              |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                               |fear         |null              |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                                      |fear         |null              |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest        |fear         |null              |\n",
            "|edge network wall quite boy those seem shoulder future fall citizen about mfa teresa harrellkenneth                                                            |fear         |null              |\n",
            "|patch for credential stuffing vulnerability released upon these story film soc allenashley millertodd                                                          |fear         |null              |\n",
            "|campaign little near enter their institution deep hacking phishing soc jenniferross samuel                                                                     |fear         |null              |\n",
            "|according remain arrive attack all form method everything democrat car very number line six space cve clintonhopkins rodney                                    |fear         |null              |\n",
            "|backup systems engaged after brute force eat couple large instead cybersecurity mfa mfa steven williamsyvette                                                  |fear         |null              |\n",
            "|coach magazine degree husband around her world enter six threatintel                                                                                           |joy          |null              |\n",
            "|product main couple design around save article finish anyone live try most arm bag control organization push dog build three firewall bethwilliams barnesbrandy|joy          |null              |\n",
            "|backup systems engaged after phishing soc ransomware phishing                                                                                                  |fear         |null              |\n",
            "|hackers bypassed the corporatesite leader your you soc cve medinawilliam                                                                                       |fear         |null              |\n",
            "|reviewing emailsystem logs street region particularly would pressure account infosec sarah darrell                                                             |fear         |null              |\n",
            "|zero breaches this quarter ransomware                                                                                                                          |fear         |null              |\n",
            "|about side pm energy scientist necessary threatintel databreach phishing                                                                                       |fear         |null              |\n",
            "|analyzing brute force attempts phishing                                                                                                                        |fear         |null              |\n",
            "|involve among half value win always group ransomware elizabethgomez                                                                                            |fear         |null              |\n",
            "|thing agent say forward us soon ten specific soc cybersecurity erik                                                                                            |fear         |null              |\n",
            "+---------------------------------------------------------------------------------------------------------------------------------------------------------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Prepare CSV Output (Sentiment + Emotion)\n",
        "# ================================\n",
        "output_df = emotion_df.select(\n",
        "    \"id\",\n",
        "    \"text\",\n",
        "    \"clean_text\",\n",
        "    \"sentiment_label\",\n",
        "    \"emotion_label\",\n",
        "    \"emotion_confidence\",\n",
        "    \"_prediction_timestamp\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "CSNWqP4taHiD"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Write ALL CSV files\n",
        "# ================================\n",
        "try:\n",
        "    output_df \\\n",
        "        .write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .csv(\"/content/final_ml_predictions\")\n",
        "\n",
        "    print(\"All CSV files written successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"CSV write failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZZHao8CaLw9",
        "outputId": "278aadd0-7fbe-47e6-965a-588737a1bc76"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All CSV files written successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = \"/content/final_ml_predictions\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QkNoiBj6aRYC"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "final_csv_path = \"/content/final_ml_predictions.csv\"\n",
        "\n",
        "# Find the part file\n",
        "for file in os.listdir(output_path):\n",
        "    if file.startswith(\"part-\") and file.endswith(\".csv\"):\n",
        "        shutil.move(\n",
        "            os.path.join(output_path, file),\n",
        "            final_csv_path\n",
        "        )\n",
        "\n",
        "print(\"Single CSV created:\", final_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFqB32I3aWTv",
        "outputId": "ec5ddd24-689a-484d-b9c9-9cd7303d691b"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single CSV created: /content/final_ml_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(final_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FbOj5QWPacnX",
        "outputId": "e761650e-6a0e-42b7-bcaa-319a9d5e56b6"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_03465b52-076a-4880-96c9-2e2c2fc52345\", \"final_ml_predictions.csv\", 62770200)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "\n",
        "print(f\"Total runtime: {round(end_time - start_time, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9X3hszuah2R",
        "outputId": "7b655a69-844d-4b29-c12d-fe403d8e6093"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total runtime: 2065.11 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znQsWCHSjDxT",
        "outputId": "1d123bbf-79ec-4499-b070-6ee42fd2e323"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "503456"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": null,
      "inputWidgetPreferences": null,
      "language": "python",
      "notebookMetadata": {
        "pythonIndentUnit": 4
      },
      "notebookName": "ml_flow_notebook",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}