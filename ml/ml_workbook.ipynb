{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "1pFxorg8Mz5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiWLFVIKE9_U",
        "outputId": "7c008c03-3add-4569-fbf9-7df7f803960b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark==3.4.1\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spark-nlp==5.4.0\n",
            "  Downloading spark_nlp-5.4.0-py2.py3-none-any.whl.metadata (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py4j==0.10.9.7 (from pyspark==3.4.1)\n",
            "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Downloading spark_nlp-5.4.0-py2.py3-none-any.whl (579 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285391 sha256=be5be793ebf6445155d3939952a19483568e5c2b7c4e2a87bedf93dbaa5d1116\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/95/1d/739a17bda5d6a1c3c6f60eed9a82f600ab0d9fcd4c601ce0da\n",
            "Successfully built pyspark\n",
            "Installing collected packages: spark-nlp, py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.9\n",
            "    Uninstalling py4j-0.10.9.9:\n",
            "      Successfully uninstalled py4j-0.10.9.9\n",
            "  Attempting uninstall: pyspark\n",
            "    Found existing installation: pyspark 4.0.1\n",
            "    Uninstalling pyspark-4.0.1:\n",
            "      Successfully uninstalled pyspark-4.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dataproc-spark-connect 1.0.1 requires pyspark[connect]~=4.0.0, but you have pyspark 3.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed py4j-0.10.9.7 pyspark-3.4.1 spark-nlp-5.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pyspark==3.4.1 spark-nlp==5.4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Spark NLP Initialization\n",
        "# ================================\n",
        "try:\n",
        "    import sparknlp\n",
        "    spark = sparknlp.start()\n",
        "    print(\"✅ Spark NLP started successfully\")\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Spark NLP start failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUmAa0RUFSFl",
        "outputId": "dcb42053-7b99-4354-a43a-25bb72dd957c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spark NLP started successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Imports\n",
        "# ================================\n",
        "try:\n",
        "    from sparknlp.base import DocumentAssembler\n",
        "    from sparknlp.annotator import (\n",
        "        Tokenizer,\n",
        "        UniversalSentenceEncoder,\n",
        "        SentimentDLModel\n",
        "    )\n",
        "    from pyspark.ml import Pipeline\n",
        "    from pyspark.sql.functions import col, current_timestamp\n",
        "    print(\"✅ Imports successful\")\n",
        "except Exception as e:\n",
        "    raise ImportError(f\"❌ Import error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIXmmRAnFYpj",
        "outputId": "fe81a236-11c0-4899-a188-5dffeadf2715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imports successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = (\n",
        "    spark.read\n",
        "    .option(\"header\", \"true\")\n",
        "    .option(\"inferSchema\", \"true\")\n",
        "    .csv(\"/content/sliver_layer__1_ (1).csv\")\n",
        ")"
      ],
      "metadata": {
        "id": "XC_IGw1IGNit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWgiHYcjJGlx",
        "outputId": "ca95c850-d688-4873-94a0-846c0092f0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Step 1: Ensure correct column name for ML\n",
        "if \"cleaned_text\" not in df.columns and \"clean_text\" in df.columns:\n",
        "    df = df.withColumnRenamed(\"clean_text\", \"cleaned_text\")\n",
        "\n",
        "# Step 2: Define required column\n",
        "REQUIRED_COL = \"cleaned_text\"\n",
        "\n",
        "# Step 3: Validation function\n",
        "def validate_input_data(df):\n",
        "    if REQUIRED_COL not in df.columns:\n",
        "        raise ValueError(f\"❌ Missing required column: {REQUIRED_COL}\")\n",
        "\n",
        "    if df.count() == 0:\n",
        "        raise ValueError(\"❌ Input DataFrame is empty\")\n",
        "\n",
        "    null_count = df.filter(col(REQUIRED_COL).isNull()).count()\n",
        "    if null_count > 0:\n",
        "        print(f\"⚠️ Warning: {null_count} null rows removed\")\n",
        "\n",
        "    return df.filter(col(REQUIRED_COL).isNotNull())\n",
        "\n",
        "# Step 4: Apply validation\n",
        "df = validate_input_data(df)\n",
        "\n",
        "# Step 5: Quick verification\n",
        "df.select(\"cleaned_text\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9HvxlF5IS5d",
        "outputId": "4f39a0df-1bd4-447f-c8b5-66f8e736b361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|cleaned_text                                                                                                                                           |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# NLP Components\n",
        "# ================================\n",
        "try:\n",
        "    document_assembler = DocumentAssembler() \\\n",
        "        .setInputCol(\"clean_text\") \\\n",
        "        .setOutputCol(\"document\")\n",
        "\n",
        "    tokenizer = Tokenizer() \\\n",
        "        .setInputCols([\"document\"]) \\\n",
        "        .setOutputCol(\"token\")\n",
        "\n",
        "    embeddings = UniversalSentenceEncoder.pretrained(\n",
        "        \"tfhub_use\", \"en\"\n",
        "    ).setInputCols([\"document\"]) \\\n",
        "     .setOutputCol(\"embeddings\")\n",
        "\n",
        "    sentiment_model = SentimentDLModel.pretrained(\n",
        "        \"sentimentdl_use_twitter\", \"en\"\n",
        "    ).setInputCols([\"embeddings\"]) \\\n",
        "     .setOutputCol(\"sentiment\")\n",
        "\n",
        "    print(\"✅ NLP components initialized\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ NLP component error: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NfmEaGzGf68",
        "outputId": "99165f2b-2b58-475d-a3dd-8084f88b234e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n",
            "sentimentdl_use_twitter download started this may take some time.\n",
            "Approximate size to download 11.4 MB\n",
            "[OK!]\n",
            "✅ NLP components initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Build Pipeline\n",
        "# ================================\n",
        "try:\n",
        "    pipeline = Pipeline(stages=[\n",
        "        document_assembler,\n",
        "        tokenizer,\n",
        "        embeddings,\n",
        "        sentiment_model\n",
        "    ])\n",
        "\n",
        "    print(\"✅ Pipeline built successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Pipeline creation failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMlKz2RiGo8o",
        "outputId": "a6154bd9-622e-4178-9ec5-944794e134a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pipeline built successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed(\"cleaned_text\", \"clean_text\")\n"
      ],
      "metadata": {
        "id": "EIP2Sh9YOmvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Run Prediction\n",
        "# ================================\n",
        "try:\n",
        "    model = pipeline.fit(df)\n",
        "    prediction_df = model.transform(df)\n",
        "\n",
        "    print(\"✅ Sentiment prediction completed\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Prediction failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgowA0MaGtIP",
        "outputId": "ae8eec1b-dc63-46ba-cb29-5a24f0ae46eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Sentiment prediction completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Extract Sentiment Label\n",
        "# ================================\n",
        "try:\n",
        "    final_df = (\n",
        "        prediction_df\n",
        "        .withColumn(\"sentiment_label\", col(\"sentiment\")[0][\"result\"])\n",
        "        .withColumn(\"_prediction_timestamp\", current_timestamp())\n",
        "    )\n",
        "\n",
        "    final_df.select(\n",
        "        \"clean_text\",\n",
        "        \"sentiment_label\"\n",
        "    ).show(10, truncate=False)\n",
        "\n",
        "    print(\"✅ Sentiment label extracted\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ Sentiment extraction failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHupzYDxG-62",
        "outputId": "31f6d388-1001-4232-9a89-a6e2e7877794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|clean_text                                                                                                                                             |sentiment_label|\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "|agent every development say quality throughout beautiful databreach                                                                                    |positive       |\n",
            "|night respond red information last everything cve blakeerik                                                                                            |positive       |\n",
            "|here grow gas enough analysis least by infosec cybersecurity mfa                                                                                       |positive       |\n",
            "|product significant world talk term herself player half have decide environment view possible mfa cve amandasanchez ogray                              |positive       |\n",
            "|environment decision wall then fire pretty how trip learn enter east much section investment on gun young catch soc soc phishing ddavis hernandezernest|positive       |\n",
            "|edge network wall quite boy those seem shoulder future fall citizen about mfa teresa harrellkenneth                                                    |positive       |\n",
            "|patch for credential stuffing vulnerability released upon these story film soc allenashley millertodd                                                  |negative       |\n",
            "|campaign little near enter their institution deep hacking phishing soc jenniferross samuel                                                             |negative       |\n",
            "|according remain arrive attack all form method everything democrat car very number line six space cve clintonhopkins rodney                            |positive       |\n",
            "|backup systems engaged after brute force eat couple large instead cybersecurity mfa mfa steven williamsyvette                                          |positive       |\n",
            "+-------------------------------------------------------------------------------------------------------------------------------------------------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "✅ Sentiment label extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_nSN14BKrXV",
        "outputId": "9e456014-f1e6-4be7-afeb-6ecdbfb4a4dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- username: string (nullable = true)\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- language: string (nullable = true)\n",
            " |-- retweet_count: integer (nullable = true)\n",
            " |-- like_count: integer (nullable = true)\n",
            " |-- reply_count: integer (nullable = true)\n",
            " |-- quote_count: integer (nullable = true)\n",
            " |-- impression_count: integer (nullable = true)\n",
            " |-- hashtags: string (nullable = true)\n",
            " |-- mentions: string (nullable = true)\n",
            " |-- source: string (nullable = true)\n",
            " |-- is_retweet: boolean (nullable = true)\n",
            " |-- is_reply: integer (nullable = true)\n",
            " |-- in_reply_to_user_id: integer (nullable = true)\n",
            " |-- conversation_id: double (nullable = true)\n",
            " |-- user_followers_count: integer (nullable = true)\n",
            " |-- user_following_count: integer (nullable = true)\n",
            " |-- user_verified: boolean (nullable = true)\n",
            " |-- user_location: string (nullable = true)\n",
            " |-- possibly_sensitive: boolean (nullable = true)\n",
            " |-- ingestion_time: timestamp (nullable = true)\n",
            " |-- clean_text: string (nullable = true)\n",
            " |-- is_reply_flag: integer (nullable = true)\n",
            " |-- document: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- token: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- embeddings: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- annotatorType: string (nullable = true)\n",
            " |    |    |-- begin: integer (nullable = false)\n",
            " |    |    |-- end: integer (nullable = false)\n",
            " |    |    |-- result: string (nullable = true)\n",
            " |    |    |-- metadata: map (nullable = true)\n",
            " |    |    |    |-- key: string\n",
            " |    |    |    |-- value: string (valueContainsNull = true)\n",
            " |    |    |-- embeddings: array (nullable = true)\n",
            " |    |    |    |-- element: float (containsNull = false)\n",
            " |-- sentiment_label: string (nullable = true)\n",
            " |-- _prediction_timestamp: timestamp (nullable = false)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Write CSV safely (Colab)\n",
        "# ================================\n",
        "try:\n",
        "    final_df \\\n",
        "        .select(\"clean_text\", \"sentiment_label\") \\\n",
        "        .coalesce(1) \\\n",
        "        .write \\\n",
        "        .mode(\"overwrite\") \\\n",
        "        .option(\"header\", \"true\") \\\n",
        "        .csv(\"/content/final_ml_predictions\")\n",
        "\n",
        "    print(\"✅ CSV written successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"❌ CSV write failed: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jENo4OzVHAT6",
        "outputId": "6e307893-28e6-4dfe-f9e8-d141c16bfe9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV written successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOoZmNarb3S",
        "outputId": "4ec81c55-ce0d-4856-96fb-28a9e841810b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "503456"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_time = time.time()\n",
        "\n",
        "print(f\"Total runtime: {round(end_time - start_time, 2)} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomy__5aMJj5",
        "outputId": "b087361d-e3f3-4212-b4ad-a03ac29a4d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total runtime: 1490.08 seconds\n"
          ]
        }
      ]
    }
  ]
}